{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tic-Tac-Toe environment\n",
    "\n",
    "The [Tic-Tac-Toe](https://github.com/MauroLuzzatto/OpenAI-Gym-TicTacToe-Environment) is a simple game environment that allows to train reinforcement learning agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://img.poki.com/cdn-cgi/image/quality=78,width=600,height=600,fit=cover,f=auto/85535e05d1f130b16751c8308cfbb19b.png\" width=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='https://img.poki.com/cdn-cgi/image/quality=78,width=600,height=600,fit=cover,f=auto/85535e05d1f130b16751c8308cfbb19b.png', width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the python modules\n",
    "import time\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gym_TicTacToe\n",
    "\n",
    "from qagent import Qagent\n",
    "from player import Player\n",
    "from utils import (\n",
    "    create_state_dictionary,\n",
    "    load_qtable,\n",
    "    play_tictactoe,\n",
    "    reshape_state,\n",
    "    save_qtable,\n",
    ")\n",
    "\n",
    "# ignore warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the tictactoe environment\n",
    "env = gym.envs.make(\"TTT-v0\", small=-1, large=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 0, 0, 1, 7, 6, 3, 0, 2, 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 10 randomly sampled actions\n",
    "[env.action_space.sample() for ii in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══╤═══╤═══╕\n",
      "│ - │ - │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "╘═══╧═══╧═══╛\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "print(env.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [0 1 0]\n",
      " [0 0 0]] -1 False\n",
      "╒═══╤═══╤═══╕\n",
      "│ - │ - │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ X │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "╘═══╧═══╧═══╛\n"
     ]
    }
   ],
   "source": [
    "color = 1\n",
    "action = 4 \n",
    "\n",
    "new_state, reward, done, _ = env.step((action, color))\n",
    "print(new_state, reward, done)\n",
    "print(env.render())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of legal states: 8953\n"
     ]
    }
   ],
   "source": [
    "state_dict = create_state_dictionary()\n",
    "state_size = env.observation_space.n\n",
    "action_size = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set training parameters\n",
    "episodes = 90_000  # 10**6 * 2\n",
    "max_steps = 9\n",
    "\n",
    "# name of the qtable when saved\n",
    "load = False\n",
    "save = True\n",
    "test = True\n",
    "\n",
    "num_test_games = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_parameters = {\n",
    "    \"learning_rate\": 1.0, \n",
    "    \"gamma\": 0.9\n",
    "}\n",
    "exploration_parameters = {\n",
    "    \"max_epsilon\": 1.0,\n",
    "    \"min_epsilon\": 0.0,\n",
    "    \"decay_rate\": 0.000005,\n",
    "\n",
    "}\n",
    "\n",
    "name = f\"qtable_{episodes}\"\n",
    "folder = \"tables\"\n",
    "\n",
    "qagent = Qagent(state_size, action_size, learning_parameters, exploration_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def play(player, state, action_space):\n",
    "\n",
    "    action = qagent.get_action(state, action_space)\n",
    "\n",
    "    # remove action from the action space\n",
    "    action_space = action_space[action_space != action]\n",
    "\n",
    "    new_state, reward, done, _ = env.step((action, player.color))\n",
    "    new_state = state_dict[reshape_state(new_state)]\n",
    "\n",
    "    qagent.qtable[state, action] = qagent.update_qtable(\n",
    "        state, new_state, action, reward, done\n",
    "    )\n",
    "    # new state\n",
    "    state = new_state\n",
    "    player.add_reward(reward)\n",
    "    return state, action_space, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 27/90000 [00:00<05:43, 262.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0,             epsilon: 1.0,             sum q-table: 3.0,             elapsed time [min]: 0.0,              done [%]: 0.0             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 10046/90000 [00:30<04:00, 333.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 10000,             epsilon: 0.01,             sum q-table: 39852.392319000006,             elapsed time [min]: 0.51,              done [%]: 11.11111111111111             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 20035/90000 [01:04<04:11, 278.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 20000,             epsilon: 0.0,             sum q-table: 39970.420419,             elapsed time [min]: 1.07,              done [%]: 22.22222222222222             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 30052/90000 [01:35<02:43, 367.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 30000,             epsilon: 0.0,             sum q-table: 39970.420419,             elapsed time [min]: 1.58,              done [%]: 33.33333333333333             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 39412/90000 [02:05<02:30, 335.93it/s]"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "player_1 = Player(color=1, episodes=episodes)\n",
    "player_2 = Player(color=2, episodes=episodes)\n",
    "\n",
    "\n",
    "for episode in tqdm(range(episodes)):\n",
    "    state = env.reset()\n",
    "    state = state_dict[reshape_state(state)]\n",
    "\n",
    "    action_space = np.arange(9)\n",
    "\n",
    "    player_1.reset_reward()\n",
    "    player_2.reset_reward()\n",
    "\n",
    "    # change start of players, randomly change the order players \n",
    "    # to start the game, integer either 0 or 1\n",
    "    start = np.random.randint(2)\n",
    "\n",
    "    for _step in range(start, max_steps + start):\n",
    "\n",
    "        # alternate the moves of the players\n",
    "        if _step % 2 == 0:\n",
    "            state, action_space, done = play(player_1, state, action_space)\n",
    "        else:\n",
    "            state, action_space, done = play(player_2, state, action_space)\n",
    "\n",
    "        if done == True:\n",
    "            break\n",
    "\n",
    "    # reduce epsilon for exporation-exploitation tradeoff\n",
    "    qagent.update_epsilon(episode)\n",
    "    player_1.save_reward(episode)\n",
    "    player_2.save_reward(episode)\n",
    "\n",
    "    if episode % 1_0000 == 0:\n",
    "\n",
    "        sum_q_table = np.sum(qagent.qtable)\n",
    "        time_passed = round((time.time() - start_time) / 60.0, 2)\n",
    "\n",
    "        print(\n",
    "            f\"episode: {episode}, \\\n",
    "            epsilon: {round(qagent.epsilon, 2)}, \\\n",
    "            sum q-table: {sum_q_table}, \\\n",
    "            elapsed time [min]: {time_passed},  \\\n",
    "            done [%]: {episode / episodes * 100} \\\n",
    "            \"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    save_qtable(qagent.qtable, folder, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the algorithm with playing against it\n",
    "play_tictactoe(env, qagent.qtable, max_steps, state_dict)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6050d35557e2eda2bee3489ac5b9239cf3ea28e67ca6bb3b65a2efaf99506245"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tictactoe_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
