{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tic-Tac-Toe environment\n",
    "\n",
    "The [Tic-Tac-Toe](https://github.com/MauroLuzzatto/OpenAI-Gym-TicTacToe-Environment) is a simple game environment that allows to train reinforcement learning agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://img.poki.com/cdn-cgi/image/quality=78,width=600,height=600,fit=cover,f=auto/85535e05d1f130b16751c8308cfbb19b.png\" width=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(\n",
    "    url=\"https://img.poki.com/cdn-cgi/image/quality=78,width=600,height=600,fit=cover,f=auto/85535e05d1f130b16751c8308cfbb19b.png\",\n",
    "    width=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the python modules\n",
    "import time\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gym_TicTacToe\n",
    "\n",
    "from src.qagent import Qagent\n",
    "from src.player import Player\n",
    "from src.play_tictactoe import play_tictactoe\n",
    "\n",
    "from src.utils import (\n",
    "    create_state_dictionary,\n",
    "    reshape_state,\n",
    "    save_qtable,\n",
    ")\n",
    "\n",
    "# ignore warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the tictactoe environment\n",
    "env = gym.envs.make(\"TTT-v0\", small=-1, large=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 5, 0, 5, 5, 6, 3, 2, 4, 1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 10 randomly sampled actions\n",
    "[env.action_space.sample() for ii in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══╤═══╤═══╕\n",
      "│ - │ - │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "╘═══╧═══╧═══╛\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "print(env.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [0 1 0]\n",
      " [0 0 0]] -1 False\n",
      "╒═══╤═══╤═══╕\n",
      "│ - │ - │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ X │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "╘═══╧═══╧═══╛\n"
     ]
    }
   ],
   "source": [
    "color = 1\n",
    "action = 4\n",
    "\n",
    "new_state, reward, done, _ = env.step((action, color))\n",
    "print(new_state, reward, done)\n",
    "print(env.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of legal states: 8953\n"
     ]
    }
   ],
   "source": [
    "state_dict = create_state_dictionary()\n",
    "state_size = env.observation_space.n\n",
    "action_size = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set training parameters\n",
    "episodes = 90_000  # 10**6 * 2\n",
    "max_steps = 9\n",
    "\n",
    "# name of the qtable when saved\n",
    "load = False\n",
    "save = True\n",
    "test = True\n",
    "\n",
    "num_test_games = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_parameters = {\"learning_rate\": 1.0, \"gamma\": 0.9}\n",
    "exploration_parameters = {\n",
    "    \"max_epsilon\": 1.0,\n",
    "    \"min_epsilon\": 0.0,\n",
    "    \"decay_rate\": 0.000005,\n",
    "}\n",
    "\n",
    "name = f\"qtable_{episodes}\"\n",
    "folder = \"tables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qagent = Qagent(state_size, action_size, learning_parameters, exploration_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def play(qagent:Qagent, player: Player, state: int, action_space: np.array) -> tuple:\n",
    "    \"\"\"this function contains the one round of game play for one player\n",
    "\n",
    "    Args:\n",
    "        qagent (Qagent): qagent to play to game\n",
    "        player (Player): player class that has its turn\n",
    "        state (int): number of the current state\n",
    "        action_space (np.arry): array with all available actions\n",
    "\n",
    "    Returns:\n",
    "        tuple: state, action_space, done\n",
    "    \"\"\"\n",
    "    action = qagent.get_action(state, action_space)\n",
    "\n",
    "    # remove action from the action space\n",
    "    action_space = action_space[action_space != action]\n",
    "\n",
    "    new_state, reward, done, _ = env.step((action, player.color))\n",
    "    new_state = state_dict[reshape_state(new_state)]\n",
    "\n",
    "    qagent.qtable[state, action] = qagent.update_qtable(\n",
    "        state, new_state, action, reward, done\n",
    "    )\n",
    "    # new state\n",
    "    state = new_state\n",
    "    player.add_reward(reward)\n",
    "    return state, action_space, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 51/2000000 [00:00<2:12:20, 251.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0,             epsilon: 1.0,             sum q-table: 2.0,             elapsed time [min]: 0.0,              done [%]: 0.0             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10035/2000000 [01:12<1:36:42, 342.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 10000,             epsilon: 0.99,             sum q-table: 95595.12738000002,             elapsed time [min]: 1.21,              done [%]: 0.5             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20054/2000000 [01:47<1:21:04, 407.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 20000,             epsilon: 0.98,             sum q-table: 134310.21514000001,             elapsed time [min]: 1.78,              done [%]: 1.0             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 30028/2000000 [02:38<2:50:22, 192.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 30000,             epsilon: 0.97,             sum q-table: 145288.93072,             elapsed time [min]: 2.64,              done [%]: 1.5             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 40025/2000000 [03:39<2:20:50, 231.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 40000,             epsilon: 0.96,             sum q-table: 149170.6773,             elapsed time [min]: 3.66,              done [%]: 2.0             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 50039/2000000 [04:25<2:23:13, 226.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 50000,             epsilon: 0.95,             sum q-table: 150339.05469999998,             elapsed time [min]: 4.42,              done [%]: 2.5             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 60004/2000000 [05:18<1:54:03, 283.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 60000,             epsilon: 0.94,             sum q-table: 151100.2896,             elapsed time [min]: 5.31,              done [%]: 3.0             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 70001/2000000 [06:41<9:41:31, 55.31it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 70000,             epsilon: 0.93,             sum q-table: 151358.4228,             elapsed time [min]: 6.69,              done [%]: 3.5000000000000004             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 80014/2000000 [09:12<9:14:22, 57.72it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 80000,             epsilon: 0.92,             sum q-table: 151251.0959,             elapsed time [min]: 9.21,              done [%]: 4.0             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 90031/2000000 [10:31<2:03:26, 257.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 90000,             epsilon: 0.91,             sum q-table: 151663.42260000002,             elapsed time [min]: 10.52,              done [%]: 4.5             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 100042/2000000 [11:27<1:56:42, 271.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 100000,             epsilon: 0.9,             sum q-table: 152165.9625,             elapsed time [min]: 11.45,              done [%]: 5.0             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 110006/2000000 [13:31<9:22:31, 56.00it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 110000,             epsilon: 0.9,             sum q-table: 152031.2191,             elapsed time [min]: 13.52,              done [%]: 5.5             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 119538/2000000 [15:23<4:02:09, 129.42it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\maurol\\OneDrive\\Dokumente\\Python_Scripts\\learn-tictactoe-through-self-play\\notebook_learn_tictactoe.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/maurol/OneDrive/Dokumente/Python_Scripts/learn-tictactoe-through-self-play/notebook_learn_tictactoe.ipynb#ch0000011?line=25'>26</a>\u001b[0m     state, action_space, done \u001b[39m=\u001b[39m play(qagent, player_1, state, action_space)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/maurol/OneDrive/Dokumente/Python_Scripts/learn-tictactoe-through-self-play/notebook_learn_tictactoe.ipynb#ch0000011?line=26'>27</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/maurol/OneDrive/Dokumente/Python_Scripts/learn-tictactoe-through-self-play/notebook_learn_tictactoe.ipynb#ch0000011?line=27'>28</a>\u001b[0m     state, action_space, done \u001b[39m=\u001b[39m play(qagent, player_2, state, action_space)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/maurol/OneDrive/Dokumente/Python_Scripts/learn-tictactoe-through-self-play/notebook_learn_tictactoe.ipynb#ch0000011?line=29'>30</a>\u001b[0m \u001b[39mif\u001b[39;00m done \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/maurol/OneDrive/Dokumente/Python_Scripts/learn-tictactoe-through-self-play/notebook_learn_tictactoe.ipynb#ch0000011?line=30'>31</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\maurol\\OneDrive\\Dokumente\\Python_Scripts\\learn-tictactoe-through-self-play\\notebook_learn_tictactoe.ipynb Cell 13'\u001b[0m in \u001b[0;36mplay\u001b[1;34m(qagent, player, state, action_space)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/maurol/OneDrive/Dokumente/Python_Scripts/learn-tictactoe-through-self-play/notebook_learn_tictactoe.ipynb#ch0000010?line=14'>15</a>\u001b[0m \u001b[39m# remove action from the action space\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/maurol/OneDrive/Dokumente/Python_Scripts/learn-tictactoe-through-self-play/notebook_learn_tictactoe.ipynb#ch0000010?line=15'>16</a>\u001b[0m action_space \u001b[39m=\u001b[39m action_space[action_space \u001b[39m!=\u001b[39m action]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/maurol/OneDrive/Dokumente/Python_Scripts/learn-tictactoe-through-self-play/notebook_learn_tictactoe.ipynb#ch0000010?line=17'>18</a>\u001b[0m new_state, reward, done, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep((action, player\u001b[39m.\u001b[39;49mcolor))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/maurol/OneDrive/Dokumente/Python_Scripts/learn-tictactoe-through-self-play/notebook_learn_tictactoe.ipynb#ch0000010?line=18'>19</a>\u001b[0m new_state \u001b[39m=\u001b[39m state_dict[reshape_state(new_state)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/maurol/OneDrive/Dokumente/Python_Scripts/learn-tictactoe-through-self-play/notebook_learn_tictactoe.ipynb#ch0000010?line=20'>21</a>\u001b[0m qagent\u001b[39m.\u001b[39mqtable[state, action] \u001b[39m=\u001b[39m qagent\u001b[39m.\u001b[39mupdate_qtable(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/maurol/OneDrive/Dokumente/Python_Scripts/learn-tictactoe-through-self-play/notebook_learn_tictactoe.ipynb#ch0000010?line=21'>22</a>\u001b[0m     state, new_state, action, reward, done\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/maurol/OneDrive/Dokumente/Python_Scripts/learn-tictactoe-through-self-play/notebook_learn_tictactoe.ipynb#ch0000010?line=22'>23</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\maurol\\anaconda3\\envs\\tictactoe_env\\lib\\site-packages\\gym\\wrappers\\order_enforcing.py:13\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/maurol/anaconda3/envs/tictactoe_env/lib/site-packages/gym/wrappers/order_enforcing.py?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m     <a href='file:///c%3A/Users/maurol/anaconda3/envs/tictactoe_env/lib/site-packages/gym/wrappers/order_enforcing.py?line=11'>12</a>\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset, \u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling reset()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='file:///c%3A/Users/maurol/anaconda3/envs/tictactoe_env/lib/site-packages/gym/wrappers/order_enforcing.py?line=12'>13</a>\u001b[0m     observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     <a href='file:///c%3A/Users/maurol/anaconda3/envs/tictactoe_env/lib/site-packages/gym/wrappers/order_enforcing.py?line=13'>14</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m observation, reward, done, info\n",
      "File \u001b[1;32mc:\\users\\maurol\\onedrive\\dokumente\\python_scripts\\tictactoe\\gym-tictactoe\\gym_TicTacToe\\envs\\tictactoe_env.py:61\u001b[0m, in \u001b[0;36mtictactoeEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/users/maurol/onedrive/dokumente/python_scripts/tictactoe/gym-tictactoe/gym_TicTacToe/envs/tictactoe_env.py?line=55'>56</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mcontains(\n\u001b[0;32m     <a href='file:///c%3A/users/maurol/onedrive/dokumente/python_scripts/tictactoe/gym-tictactoe/gym_TicTacToe/envs/tictactoe_env.py?line=56'>57</a>\u001b[0m     action\n\u001b[0;32m     <a href='file:///c%3A/users/maurol/onedrive/dokumente/python_scripts/tictactoe/gym-tictactoe/gym_TicTacToe/envs/tictactoe_env.py?line=57'>58</a>\u001b[0m ), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthis action \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00maction\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is not in action_space\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/users/maurol/onedrive/dokumente/python_scripts/tictactoe/gym-tictactoe/gym_TicTacToe/envs/tictactoe_env.py?line=59'>60</a>\u001b[0m reward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msmall  \u001b[39m# give (negative) reward for every move done\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/users/maurol/onedrive/dokumente/python_scripts/tictactoe/gym-tictactoe/gym_TicTacToe/envs/tictactoe_env.py?line=60'>61</a>\u001b[0m (row, col) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecode_action(action)\n\u001b[0;32m     <a href='file:///c%3A/users/maurol/onedrive/dokumente/python_scripts/tictactoe/gym-tictactoe/gym_TicTacToe/envs/tictactoe_env.py?line=61'>62</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate[row, col] \u001b[39m=\u001b[39m color  \u001b[39m# postion the token on the field\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/users/maurol/onedrive/dokumente/python_scripts/tictactoe/gym-tictactoe/gym_TicTacToe/envs/tictactoe_env.py?line=62'>63</a>\u001b[0m done \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_winner(color)\n",
      "File \u001b[1;32mc:\\users\\maurol\\onedrive\\dokumente\\python_scripts\\tictactoe\\gym-tictactoe\\gym_TicTacToe\\envs\\tictactoe_env.py:114\u001b[0m, in \u001b[0;36mtictactoeEnv.decode_action\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/users/maurol/onedrive/dokumente/python_scripts/tictactoe/gym-tictactoe/gym_TicTacToe/envs/tictactoe_env.py?line=111'>112</a>\u001b[0m out\u001b[39m.\u001b[39mappend(i \u001b[39m%\u001b[39m \u001b[39m3\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/users/maurol/onedrive/dokumente/python_scripts/tictactoe/gym-tictactoe/gym_TicTacToe/envs/tictactoe_env.py?line=112'>113</a>\u001b[0m i \u001b[39m=\u001b[39m i \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m3\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/users/maurol/onedrive/dokumente/python_scripts/tictactoe/gym-tictactoe/gym_TicTacToe/envs/tictactoe_env.py?line=113'>114</a>\u001b[0m out\u001b[39m.\u001b[39;49mappend(i)\n\u001b[0;32m    <a href='file:///c%3A/users/maurol/onedrive/dokumente/python_scripts/tictactoe/gym-tictactoe/gym_TicTacToe/envs/tictactoe_env.py?line=114'>115</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m i \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/users/maurol/onedrive/dokumente/python_scripts/tictactoe/gym-tictactoe/gym_TicTacToe/envs/tictactoe_env.py?line=115'>116</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mreversed\u001b[39m(out)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "player_1 = Player(color=1, episodes=episodes)\n",
    "player_2 = Player(color=2, episodes=episodes)\n",
    "\n",
    "\n",
    "for episode in tqdm(range(episodes)):\n",
    "    state = env.reset()\n",
    "    state = state_dict[reshape_state(state)]\n",
    "\n",
    "    action_space = np.arange(9)\n",
    "\n",
    "    player_1.reset_reward()\n",
    "    player_2.reset_reward()\n",
    "\n",
    "    # randomly change the order players\n",
    "    # to start the game, integer either 0 or 1\n",
    "    start = np.random.randint(2)\n",
    "\n",
    "    for _step in range(start, max_steps + start):\n",
    "\n",
    "        # alternate the moves of the players\n",
    "        if _step % 2 == 0:\n",
    "            state, action_space, done = play(qagent, player_1, state, action_space)\n",
    "        else:\n",
    "            state, action_space, done = play(qagent, player_2, state, action_space)\n",
    "\n",
    "        if done == True:\n",
    "            break\n",
    "\n",
    "    # reduce epsilon for exporation-exploitation tradeoff\n",
    "    qagent.update_epsilon(episode)\n",
    "    player_1.save_reward(episode)\n",
    "    player_2.save_reward(episode)\n",
    "\n",
    "    if episode % 1_0000 == 0:\n",
    "\n",
    "        sum_q_table = np.sum(qagent.qtable)\n",
    "        time_passed = round((time.time() - start_time) / 60.0, 2)\n",
    "\n",
    "        print(\n",
    "            f\"episode: {episode}, \\\n",
    "            epsilon: {round(qagent.epsilon, 2)}, \\\n",
    "            sum q-table: {sum_q_table}, \\\n",
    "            elapsed time [min]: {time_passed},  \\\n",
    "            done [%]: {episode / episodes * 100} \\\n",
    "            \"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qtable_90000.npy saved!\n"
     ]
    }
   ],
   "source": [
    "qtable = qagent.get_qtable()\n",
    "save_qtable(qtable, folder, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human beginns\n",
      "--------------------\n",
      "╒═══╤═══╤═══╕\n",
      "│ - │ - │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "╘═══╧═══╧═══╛\n",
      "--------------------\n",
      "Move Human\n",
      "Action: 5\n",
      "-1\n",
      "--------------------\n",
      "move Agent\n",
      "Action: 0\n",
      "╒═══╤═══╤═══╕\n",
      "│ O │ - │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ X │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "╘═══╧═══╧═══╛\n",
      "--------------------\n",
      "Move Human\n",
      "Action: 4\n",
      "-1\n",
      "--------------------\n",
      "move Agent\n",
      "Action: 1\n",
      "╒═══╤═══╤═══╕\n",
      "│ O │ O │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ X │ X │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "╘═══╧═══╧═══╛\n",
      "--------------------\n",
      "Move Human\n",
      "Action: 3\n",
      "9\n",
      "********************\n",
      "Human won!\n",
      "********************\n",
      "╒═══╤═══╤═══╕\n",
      "│ O │ O │ - │\n",
      "├───┼───┼───┤\n",
      "│ X │ X │ X │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "╘═══╧═══╧═══╛\n",
      "\n",
      "\n",
      "\n",
      "Agent beginns\n",
      "--------------------\n",
      "--------------------\n",
      "move Agent\n",
      "Action: 0\n",
      "╒═══╤═══╤═══╕\n",
      "│ O │ - │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "╘═══╧═══╧═══╛\n",
      "--------------------\n",
      "Move Human\n",
      "Action: 4\n",
      "-1\n",
      "--------------------\n",
      "move Agent\n",
      "Action: 1\n",
      "╒═══╤═══╤═══╕\n",
      "│ O │ O │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ X │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "╘═══╧═══╧═══╛\n",
      "--------------------\n",
      "Move Human\n",
      "Action: 5\n",
      "-1\n",
      "--------------------\n",
      "move Agent\n",
      "Action: 6\n",
      "╒═══╤═══╤═══╕\n",
      "│ O │ O │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ X │ X │\n",
      "├───┼───┼───┤\n",
      "│ O │ - │ - │\n",
      "╘═══╧═══╧═══╛\n",
      "--------------------\n",
      "Move Human\n",
      "Action: 3\n",
      "9\n",
      "********************\n",
      "Human won!\n",
      "********************\n",
      "╒═══╤═══╤═══╕\n",
      "│ O │ O │ - │\n",
      "├───┼───┼───┤\n",
      "│ X │ X │ X │\n",
      "├───┼───┼───┤\n",
      "│ O │ - │ - │\n",
      "╘═══╧═══╧═══╛\n",
      "\n",
      "\n",
      "\n",
      "Human beginns\n",
      "--------------------\n",
      "╒═══╤═══╤═══╕\n",
      "│ - │ - │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "╘═══╧═══╧═══╛\n",
      "--------------------\n",
      "Move Human\n",
      "Action: 4\n",
      "-1\n",
      "--------------------\n",
      "move Agent\n",
      "Action: 0\n",
      "╒═══╤═══╤═══╕\n",
      "│ O │ - │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ X │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "╘═══╧═══╧═══╛\n",
      "--------------------\n",
      "Move Human\n",
      "Action: 8\n",
      "-1\n",
      "--------------------\n",
      "move Agent\n",
      "Action: 5\n",
      "╒═══╤═══╤═══╕\n",
      "│ O │ - │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ X │ O │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ X │\n",
      "╘═══╧═══╧═══╛\n",
      "--------------------\n",
      "Move Human\n",
      "Action: 2\n",
      "-1\n",
      "--------------------\n",
      "move Agent\n",
      "Action: 1\n",
      "╒═══╤═══╤═══╕\n",
      "│ O │ O │ X │\n",
      "├───┼───┼───┤\n",
      "│ - │ X │ O │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ X │\n",
      "╘═══╧═══╧═══╛\n",
      "--------------------\n",
      "Move Human\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\maurol\\OneDrive\\Dokumente\\Python_Scripts\\learn-tictactoe-through-self-play\\notebook_learn_tictactoe.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/maurol/OneDrive/Dokumente/Python_Scripts/learn-tictactoe-through-self-play/notebook_learn_tictactoe.ipynb#ch0000012?line=0'>1</a>\u001b[0m \u001b[39m# test the algorithm with playing against it\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/maurol/OneDrive/Dokumente/Python_Scripts/learn-tictactoe-through-self-play/notebook_learn_tictactoe.ipynb#ch0000012?line=1'>2</a>\u001b[0m play_tictactoe(env, qagent\u001b[39m.\u001b[39;49mqtable, max_steps, state_dict)\n",
      "File \u001b[1;32mc:\\Users\\maurol\\OneDrive\\Dokumente\\Python_Scripts\\learn-tictactoe-through-self-play\\utils.py:119\u001b[0m, in \u001b[0;36mplay_tictactoe\u001b[1;34m(env, qtable, max_steps, state_dict, num_test_games)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/maurol/OneDrive/Dokumente/Python_Scripts/learn-tictactoe-through-self-play/utils.py?line=115'>116</a>\u001b[0m action \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan\n\u001b[0;32m    <a href='file:///c%3A/Users/maurol/OneDrive/Dokumente/Python_Scripts/learn-tictactoe-through-self-play/utils.py?line=117'>118</a>\u001b[0m \u001b[39mwhile\u001b[39;00m action \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m action_space:\n\u001b[1;32m--> <a href='file:///c%3A/Users/maurol/OneDrive/Dokumente/Python_Scripts/learn-tictactoe-through-self-play/utils.py?line=118'>119</a>\u001b[0m     action \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(\n\u001b[0;32m    <a href='file:///c%3A/Users/maurol/OneDrive/Dokumente/Python_Scripts/learn-tictactoe-through-self-play/utils.py?line=119'>120</a>\u001b[0m         \u001b[39minput\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mchoose an action from \u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m: \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(action_space))\n\u001b[0;32m    <a href='file:///c%3A/Users/maurol/OneDrive/Dokumente/Python_Scripts/learn-tictactoe-through-self-play/utils.py?line=120'>121</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/maurol/OneDrive/Dokumente/Python_Scripts/learn-tictactoe-through-self-play/utils.py?line=121'>122</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAction:\u001b[39m\u001b[39m\"\u001b[39m, action)\n\u001b[0;32m    <a href='file:///c%3A/Users/maurol/OneDrive/Dokumente/Python_Scripts/learn-tictactoe-through-self-play/utils.py?line=122'>123</a>\u001b[0m action_space \u001b[39m=\u001b[39m action_space[action_space \u001b[39m!=\u001b[39m action]\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "# test the algorithm with playing against it\n",
    "play_tictactoe(env, qtable, max_steps, state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6050d35557e2eda2bee3489ac5b9239cf3ea28e67ca6bb3b65a2efaf99506245"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tictactoe_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
